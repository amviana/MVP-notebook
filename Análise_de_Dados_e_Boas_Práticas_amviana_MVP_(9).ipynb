{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmYX3PLx58Jg"
      },
      "source": [
        "# MVP Análise de Dados e Boas Práticas\n",
        "\n",
        "**Nome:** Arielen de Morais Viana\n",
        "\n",
        "**Matrícula:** 4052023001299\n",
        "\n",
        "**Dataset:** [Supermarket store branches sales analysis](https://www.kaggle.com/datasets/surajjha101/stores-area-and-sales-data?resource=download)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW_JS-EEBFaR"
      },
      "source": [
        "# Definição do Problema\n",
        "\n",
        "Este projeto tem como objetivo realizar uma análise exploratória e pré-processamento de dados relacionados às vendas em lojas de varejo. Atraves desse estudo, será possível compreender melhor os fatores que influenciam os resultados de vendas, como área da loja, número de itens disponiveis e fluxo diário de clientes.\n",
        "\n",
        "Este projeto não envolve criação de modelo preditivo, e sim análise exploratória. Portanto, o problema é classificado como **não supervisionado**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm6mOo5PBYwr"
      },
      "source": [
        "## Hipóteses do Problema\n",
        "\n",
        "Algumas hipóteses iniciais consideradas são:\n",
        "\n",
        "- Lojas com maior área física tendem a apresentar vendas maiores.\n",
        "- A quantidade de clientes atendidos diariamente tem forte correlação com o volume de vendas.\n",
        "- Lojas com maior variedade de itens disponíveis podem atender melhor às necessidades dos clientes e, consequentemente, vender mais.\n",
        "\n",
        "Essas hipóteses serão investigadas com base na análise exploratória dos dados disponíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1zNNZt6BfdF"
      },
      "source": [
        "## Tipo de Problema\n",
        "\n",
        "Apesar de o dataset conter uma variável que poderia ser utilizada como alvo (`Store_Sales`), optei por não realizar uma modelagem supervisionada, pois o objetivo deste projeto está focado na análise exploratória e compreensão dos padrões presentes nos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N91bTLbiBxrm"
      },
      "source": [
        "## Seleção de Dados\n",
        "\n",
        "O conjunto de dados utilizado foi obtido em um repositório público (Kaggle) e contém informações agregadas sobre lojas de varejo. Os dados são fictícios, anonimizados e refletem métricas operacionais como vendas, fluxo de clientes, quantidade de itens e área da loja.\n",
        "\n",
        "Critérios de seleção:\n",
        "- Dataset público e gratuito\n",
        "- Estrutura simples, com dados contínuos e categóricos\n",
        "- Compatível com os objetivos do projeto de análise exploratória"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC6QJHhWBnzH"
      },
      "source": [
        "## Atributos do Dataset\n",
        "\n",
        "A base de dados é composta pelos seguintes atributos:\n",
        "\n",
        "- `Store ID`: identificador único de cada loja\n",
        "- `Store_Area`: área total da loja (em metros ou pés quadrados)\n",
        "- `Items_Available`: número total de itens disponíveis para venda\n",
        "- `Daily_Customer_Count`: média de clientes atendidos por dia\n",
        "- `Store_Sales`: total de vendas da loja (valor monetário)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DObGnkf0bJBh"
      },
      "source": [
        "# Importação das Bibliotecas Necessárias e Carga de Dados\n",
        "\n",
        "Nesta etapa, serão importadas as bibliotecas que serão utilizadas ao longo do projeto, como `pandas` para manipulação de dados, `matplotlib` e `seaborn` para criação de gráficos. Em seguida, será realizado o carregamento do conjunto de dados para análise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCohWn2jbkDB"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas principais\n",
        "import pandas as pd            # manipulação de dados\n",
        "import matplotlib.pyplot as plt  # criação de gráficos\n",
        "import seaborn as sns          # visualizações avançadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIokzI3xb8_t"
      },
      "outputs": [],
      "source": [
        "# Configurações visuais para os gráficos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette('pastel')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCPbhofsE59F"
      },
      "outputs": [],
      "source": [
        "# Carregamento do dataset\n",
        "# Substitua o nome abaixo se seu arquivo for diferente\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/amviana/MVP-notebook/main/Stores.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKb_BDQ6E6sR"
      },
      "outputs": [],
      "source": [
        "# Visualização das primeiras linhas\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcHpQ9s_B4n1"
      },
      "source": [
        "# Análise de Dados\n",
        "\n",
        "Nesta etapa, será feita uma análise inicial dos dados com o objetivo de compreender sua estrutura, tipos de variáveis, existência de valores ausentes ou inconsistentes e o comportamento estatístico das principais colunas. A partir dessas informações, será possível levantar insights e hipóteses mais embasadas para as etapas seguintes do projeto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kuan1F5EA8J"
      },
      "source": [
        "## Total e Tipo das Instâncias\n",
        "\n",
        "O dataset analisado possui **896 instâncias (observações)**, com informações agregadas sobre diferentes lojas de varejo. Os cinco atributos disponíveis são todos de **tipo numérico (inteiro ou decimal)**, o que permite a aplicação direta de métodos estatísticos e de visualização.\n",
        "\n",
        "Não há atributos categóricos neste conjunto de dados. Além disso, nenhuma coluna apresenta valores ausentes, o que facilita o processo de análise e pré-processamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3asH5qmbHKVe"
      },
      "outputs": [],
      "source": [
        "# Verificando o número de linhas e colunas\n",
        "print(\"Dimensão do dataset:\", df.shape)\n",
        "\n",
        "# Verificando o nome das colunas e os tipos de dados\n",
        "print(\"\\nTipos de dados:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Verificando se há valores ausentes\n",
        "print(\"\\nValores ausentes por coluna:\")\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-50BJtJH91B"
      },
      "outputs": [],
      "source": [
        "# Criando categorias de vendas\n",
        "df['Faixa_de_Vendas'] = pd.cut(df['Store_Sales'],\n",
        "                               bins=[0, 30000, 60000, 90000, 120000],\n",
        "                               labels=['Baixa', 'Média', 'Alta', 'Muito Alta'])\n",
        "\n",
        "# Gráfico de barras com cores diferentes e rótulos de dados\n",
        "plt.figure(figsize=(7, 5))\n",
        "ax = sns.countplot(x='Faixa_de_Vendas', hue='Faixa_de_Vendas', data=df,\n",
        "                   palette='Blues', legend=False)\n",
        "\n",
        "plt.title('Distribuição das Lojas por Faixa de Vendas')\n",
        "plt.xlabel('Faixa de Vendas')\n",
        "plt.ylabel('Quantidade de Lojas')\n",
        "\n",
        "# Adicionando os rótulos em cima das barras\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.annotate(f'{height}',\n",
        "                (p.get_x() + p.get_width() / 2., height),\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3kgJV4BJC9B"
      },
      "source": [
        "O gráfico de barras mostra a distribuição das lojas de acordo com a faixa de vendas. A maioria das lojas está concentrada nas faixas \"Média\" e \"Alta\", enquanto poucas apresentam vendas \"Muito Altas\" ou \"Baixas\", sugerindo uma tendência centralizada nas faixas intermediárias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-bS4g_ECPoP"
      },
      "source": [
        "## Estatísticas Descritivas\n",
        "\n",
        "Estatisticas descritivas fornecem um resumo das características numéricas do dataset. São úteis para entender a distribuição, tendência central e dispersão dos dados. As principais métricas incluem:\n",
        "\n",
        "- **Média (mean)**: valor médio.\n",
        "- **Desvio padrão (std)**: grau de dispersão em relação à média.\n",
        "- **Mínimo e Máximo (min, max)**: valores extremos.\n",
        "- **Quartis (25%, 50%, 75%)**: dividem a distribuição em partes iguais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTCOuOolC_rG"
      },
      "outputs": [],
      "source": [
        "# estatísticas descritivas básicas do dataset\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7h3GAMUJ0cK"
      },
      "source": [
        "A partir da tabela, observamos que:\n",
        "\n",
        "- A **área das lojas (Store_Area)** varia entre 775 e 2.229 m², com média de aproximadamente 1.485 m².\n",
        "- O número de **itens disponíveis (Items_Available)** varia de 932 a 2.667, com média de 1.782.\n",
        "- O fluxo diário de clientes (**Daily_Customer_Count**) varia entre 10 e 1.560 pessoas por dia, com média de 786.\n",
        "- Já as **vendas totais (Store_Sales)** variam entre R\\$ 14.920,00 e R\\$ 116.320,00, com média de R$ 59.351,00.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWPH7rj8Ck6v"
      },
      "source": [
        "### Média\n",
        "\n",
        "A média é uma medida de tendência central que representa o valor típico ou o ponto de equilíbrio de um conjunto de dados. É calculada somando-se todos os valores e dividindo-se pelo número total de observações. É sensível a valores extremos (outliers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm3QIAb-CZbt"
      },
      "outputs": [],
      "source": [
        "# Média de cada atributo numérico\n",
        "df.describe().loc['mean']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPKpanMFCf0e"
      },
      "outputs": [],
      "source": [
        "# Valores das médias\n",
        "mean_values = df.describe().loc['mean']\n",
        "\n",
        "# Gráfico de barras com os valores das médias\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(mean_values.index, mean_values.values, color='skyblue')\n",
        "\n",
        "plt.title('Média dos Atributos Numéricos')\n",
        "plt.ylabel('Valor Médio')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adicionando rótulos com os valores\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 500, f'{yval:.0f}', ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6Fh28dGLUVP"
      },
      "source": [
        "O gráfico de barras é ideal para representar medidas agregadas, como médias. Ele facilita a visualização e comparação entre as variáveis.\n",
        "\n",
        "**Observação:**\n",
        "A variável `Store_Sales` tem uma média bem maior do que as outras, o que pode acabar distorcendo a visualização dos dados. Caso fosse necessário analisar as demais com mais clareza, seria possível aplicar uma transformação ou normalização dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHRKK0YmCmUw"
      },
      "source": [
        "### Desvio Padrão\n",
        "\n",
        "O desvio padrão é uma medida de dispersão que quantifica a quantidade de variação ou dispersão de um conjunto de valores. Um desvio padrão baixo indica que os pontos de dados tendem a estar próximos da média do conjunto, enquanto um desvio padrão alto indica que os pontos de dados estão espalhados por uma faixa maior de valores. Ele é a raiz quadrada da variância."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBIXqi0fCwSH"
      },
      "outputs": [],
      "source": [
        "# desvio padrão dos atributos numéricos do dataset\n",
        "df.describe().loc['std']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd9Ma5vUMohq"
      },
      "outputs": [],
      "source": [
        "std_values = df.describe().loc['std']\n",
        "\n",
        "# Gráfico de barras com rótulos de dados\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(std_values.index, std_values.values, color='salmon')\n",
        "\n",
        "plt.title('Desvio Padrão dos Atributos Numéricos')\n",
        "plt.ylabel('Valor do Desvio Padrão')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adiciona os valores acima de cada barra\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 500, f'{yval:.0f}', ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_v1ImkCDHYw"
      },
      "outputs": [],
      "source": [
        "# Removendo Store_Sales da visualização para melhorar a comparação\n",
        "std_values_excl = std_values.drop('Store_Sales')\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(std_values_excl.index, std_values_excl.values, color='darkcyan')\n",
        "\n",
        "plt.title('Desvio Padrão dos Atributos (sem Store_Sales)')\n",
        "plt.ylabel('Valor do Desvio Padrão')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 5, f'{yval:.0f}', ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwn8sDXtOTws"
      },
      "source": [
        "No primeiro gráfico, exibimos o desvio padrão de todos os atributos. Porém, a variável **`Store_Sales`** possui um valor muito mais alto do que as demais, o que acaba distorcendo o gráfico e dificultando a visualização dos outros atributos.\n",
        "\n",
        "Por isso, também foi criado um **segundo gráfico**, excluindo a variável `Store_Sales`. Dessa forma, conseguimos observar melhor as diferenças de dispersão entre os outros atributos do dataset.\n",
        "\n",
        "**Gráfico utilizado:**  \n",
        "Utilizamos o **gráfico de barras**, pois ele é ideal para comparar a variação entre atributos numéricos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tX_H2zZEFwU"
      },
      "source": [
        "## Histograma\n",
        "\n",
        "Os histogramas com linha de densidade (KDE) mostram como os principais atributos numéricos do dataset estão distribuídos. A maioria deles apresenta uma distribuição simétrica, com formato semelhante ao de uma curva normal.\n",
        "\n",
        "Esse tipo de visualização ajuda a entender o comportamento geral de cada variável e identificar padrões, como assimetrias, picos ou dispersões. Além disso, facilita a comparação entre atributos para descobrir quais têm comportamento mais concentrado ou mais disperso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSs4jBF7HUnV"
      },
      "source": [
        "### *Distribuição dos Atributos Mais Relevantes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdBuOXxzHI5h"
      },
      "outputs": [],
      "source": [
        "# **Histogramas com Curva de Densidade (KDE)**\n",
        "# Gerando histogramas com linha de densidade para os atributos numéricos relevantes\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lista de colunas numéricas (excluindo o Store_ID)\n",
        "colunas_numericas = ['Store_Area', 'Items_Available', 'Daily_Customer_Count', 'Store_Sales']\n",
        "\n",
        "# Tamanho da figura\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Loop para criar subplots\n",
        "for i, coluna in enumerate(colunas_numericas):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    sns.histplot(data=df, x=coluna, kde=True, bins=30, color='mediumseagreen', edgecolor='black')\n",
        "    plt.title(f'Distribuição de {coluna}')\n",
        "    plt.xlabel(coluna)\n",
        "    plt.ylabel('Frequência')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.suptitle('Distribuição dos Atributos Numéricos com Curva de Densidade (KDE)', fontsize=16)\n",
        "plt.tight_layout(pad=2.0, rect=[0, 0, 1, 0.95])  # espaço para o título geral\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7CSWH48HI5h"
      },
      "source": [
        "Acima temos os histogramas com curvas de densidade (KDE) dos principais atributos numéricos do dataset, o que nos ajuda a entender melhor a distribuição dos dados:\n",
        "\n",
        "- **Área da Loja (Store_Area)**: Apresenta uma distribuição relativamente simétrica e concentrada em torno da média (~1500 m²), com leve tendência à normalidade.\n",
        "- **Itens Disponíveis (Items_Available)**: Segue uma distribuição próxima do formato normal, com um pico em torno de 1800 itens. Isso indica que a maioria das lojas oferece uma quantidade similar de produtos.\n",
        "- **Clientes Diários (Daily_Customer_Count)**: A distribuição também é aproximadamente simétrica, com a maioria das lojas recebendo entre 600 e 900 clientes por dia.\n",
        "- **Vendas por Loja (Store_Sales)**: Apesar de ter uma curva relativamente suave, nota-se uma leve assimetria à direita (distribuição um pouco enviesada), o que indica a presença de algumas lojas com vendas consideravelmente mais altas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av_qTo2YERdw"
      },
      "source": [
        "## Boxplot\n",
        "\n",
        "Para entender como os atributos numéricos se comportam em diferentes contextos de vendas, vamos agrupá-los por Faixa de Vendas. Isso nos permite visualizar como variáveis como área da loja, número de clientes diários, itens disponíveis e vendas totais se distribuem em lojas com baixa, média, alta e muito alta performance.\n",
        "\n",
        "Essa abordagem ajuda a identificar padrões ou diferenças relevantes entre as faixas — por exemplo, se lojas com vendas muito altas tendem a ter mais itens disponíveis, ou se o número de clientes diários influencia diretamente no desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH6ov-UMHHHJ"
      },
      "outputs": [],
      "source": [
        "# Estatísticas descritivas por faixa de vendas (sem FutureWarning)\n",
        "df.groupby('Faixa_de_Vendas', observed=True).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL3TPaIRJydo"
      },
      "source": [
        "### *Área da loja* por Faixa de Venda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spO_61dYJ3c9"
      },
      "outputs": [],
      "source": [
        "# Boxplot da área das lojas em cada faixa de vendas\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Faixa_de_Vendas', y='Store_Area', data=df,\n",
        "            hue='Faixa_de_Vendas', palette='pastel', legend=False)\n",
        "plt.title('Área da Loja por Faixa de Vendas')\n",
        "plt.xlabel('Faixa de Vendas')\n",
        "plt.ylabel('Área da Loja (m²)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SkLRoCnJ-67"
      },
      "source": [
        "Este boxplot mostra a distribuição da **área das lojas (em m²)** para cada **faixa de vendas** (Baixa, Média, Alta e Muito Alta).\n",
        "\n",
        "**Principais insights:**\n",
        "- A mediana da área das lojas **aumenta conforme a faixa de vendas sobe**, indicando que lojas maiores tendem a vender mais.\n",
        "- Apesar disso, há **variação dentro de cada grupo**: algumas lojas menores aparecem em faixas de vendas mais altas, o que sugere que **o tamanho não é o único fator determinante das vendas**.\n",
        "- Na faixa “Muito Alta”, por exemplo, existem **lojas pequenas com vendas elevadas**, que se destacam como outliers.\n",
        "\n",
        "Esse gráfico nos ajuda a entender **como a área da loja pode influenciar (ou não)** o desempenho em vendas, além de revelar possíveis exceções que merecem atenção estratégica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mom9h5YLZUDz"
      },
      "source": [
        "### *Clientes Diários* por Faixa de Venda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZJ5Z91ZZdWJ"
      },
      "outputs": [],
      "source": [
        "# Boxplot do número de clientes diários em cada faixa de vendas\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Faixa_de_Vendas', y='Daily_Customer_Count', data=df,\n",
        "            hue='Faixa_de_Vendas', palette='pastel', legend=False)\n",
        "plt.title('Clientes Diários por Faixa de Vendas')\n",
        "plt.xlabel('Faixa de Vendas')\n",
        "plt.ylabel('Clientes Diários')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15WvKecPaG8c"
      },
      "source": [
        "O gráfico mostra que lojas com faixas de vendas mais altas tendem a ter uma maior mediana de clientes diários. No entanto, as distribuições se sobrepõem bastante, indicando que o volume de clientes, embora importante, não é o único fator que define a faixa de vendas. Algumas lojas com menos clientes ainda conseguem alto desempenho, possivelmente por ticket médio mais elevado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgR-fjkxaW97"
      },
      "source": [
        "### *Itens Disponiveis* por Faixa de Venda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XbhCu0vaa31"
      },
      "outputs": [],
      "source": [
        "# Boxplot da quantidade de itens disponíveis em cada faixa de vendas\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Faixa_de_Vendas', y='Items_Available', data=df,\n",
        "            hue='Faixa_de_Vendas', palette='pastel', legend=False)\n",
        "plt.title('Itens Disponíveis por Faixa de Vendas')\n",
        "plt.xlabel('Faixa de Vendas')\n",
        "plt.ylabel('Itens Disponíveis')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhxBGsHuaymb"
      },
      "source": [
        "A distribuição do número de itens disponíveis por faixa de vendas mostra que lojas com maior faturamento tendem a oferecer mais itens. A mediana dos grupos mais altos de venda é ligeiramente maior, o que pode indicar que a variedade de produtos influencia no desempenho de vendas. No entanto, também há sobreposição entre as faixas, o que sugere que apenas ter mais itens disponíveis não garante um melhor desempenho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_oJr2m-23Ov"
      },
      "source": [
        "### *Distribuição de Lojas* por Faixa de Venda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hox49JCHcyQg"
      },
      "outputs": [],
      "source": [
        "# Gráfico de barras para visualizar a quantidade de lojas em cada faixa de vendas\n",
        "df['Faixa_de_Vendas'].value_counts().plot(kind='bar', color='skyblue')\n",
        "plt.title('Distribuição de Lojas por Faixa de Vendas')\n",
        "plt.xlabel('Faixa de Vendas')\n",
        "plt.ylabel('Quantidade de Lojas')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-HszO3p3CoG"
      },
      "source": [
        "**Principais insights:**\n",
        "- A maior parte das lojas está concentrada nas faixas Média e Alta, indicando que esses são os desempenhos mais comuns no dataset.\n",
        "- As faixas Muito Alta e Baixa possuem significativamente menos lojas, o que pode sugerir oportunidade de expansão ou ações específicas para esses extremos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYbwraF4O6IY"
      },
      "source": [
        "## Análise de Outliers\n",
        "Os outliers são valores extremos que fogem da tendência central dos dados e podem representar situações atípicas, erros de medição ou oportunidades estratégicas. Para identificá-los, utilizamos gráficos de boxplot para cada variável numérica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o5BEwXzyPBSN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "# Remove colunas com 'id' no nome, mesmo sendo numéricas\n",
        "numeric_cols = [\n",
        "    col for col in df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    if 'id' not in col.lower()\n",
        "]\n",
        "\n",
        "# Layout\n",
        "num_vars = len(numeric_cols)\n",
        "cols = 2\n",
        "rows = math.ceil(num_vars / cols)\n",
        "\n",
        "plt.figure(figsize=(12, 4 * rows))\n",
        "\n",
        "# Plota os boxplots\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    sns.boxplot(data=df, y=col, color='lightblue')\n",
        "    plt.title(f'Outliers em {col}')\n",
        "    plt.ylabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxukd0d1PGGm"
      },
      "source": [
        "Pelo gráfico, dá pra perceber que algumas lojas têm um faturamento bem acima da média, o que chama atenção. O número de clientes por dia também tem alguns pontos fora do comum, indicando lojas com um fluxo muito maior que o esperado. Essas exceções podem representar oportunidades interessantes, como estar em uma localização boa ou ter alguma promoção, e por isso valem uma análise mais detalhada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_ERHJAPEZAt"
      },
      "source": [
        "## Matriz de Correlação\n",
        "\n",
        "A matriz de correlação mede a força e a direção de uma relação linear que os atributos numéricos das espécies podem ter. Valores próximos a 1 indicam uma forte correlação positiva, -1 uma forte correlação negativa, e 0 ausência de correlação linear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jAmPsbzDHF2t"
      },
      "outputs": [],
      "source": [
        "# Matriz de correlação entre as variáveis numéricas do dataset\n",
        "print(\"\\nMatriz de Correlação:\")\n",
        "print(df[['Store_Area', 'Items_Available', 'Daily_Customer_Count', 'Store_Sales']].corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1iSnofo-HF2u"
      },
      "outputs": [],
      "source": [
        "# Mapa de calor das correlações numéricas\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df[['Store_Area', 'Items_Available', 'Daily_Customer_Count', 'Store_Sales']].corr(),\n",
        "            annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Matriz de Correlação das Variáveis Numéricas do Dataset de Lojas')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz1caOiQHF2u"
      },
      "source": [
        "A matriz de correlação mostra que as vendas estão bem relacionadas ao tamanho da loja e à quantidade de produtos disponíveis. Ou seja, quanto maior a loja e maior a variedade, maior tende a ser o faturamento. Já o número de clientes por dia quase não tem relação com as vendas, o que sugere que, neste caso, atrair mais gente não significa necessariamente vender mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC1f5d_BGTVB"
      },
      "source": [
        "## Tratamento de Valores Nulos\n",
        "\n",
        "O tratamento de valores nulos é uma etapa fundamental na análise de dados, pois valores ausentes podem comprometer a qualidade das análises. No caso do dataset de lojas, verificamos se há valores nulos nas colunas numéricas e categóricas principais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fNQUvAnwG8fL"
      },
      "outputs": [],
      "source": [
        "# Verificar a presença de valores nulos no dataset de lojas\n",
        "print(\"Valores nulos no dataset de lojas:\")\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWdahJxX3yv_"
      },
      "source": [
        "Não foram encontrados valores nulos no dataset de lojas, o que dispensa a necessidade de imputações ou remoção de dados nesta etapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p2d8qIT84Qy9"
      },
      "outputs": [],
      "source": [
        "# Gráfico opcional para visualização de valores nulos\n",
        "# plt.figure(figsize=(8, 4))\n",
        "# sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
        "# plt.title('Visualização de Valores Nulos no Dataset')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDovmxgDFcbF"
      },
      "source": [
        "# Pré-Processamento de Dados\n",
        "\n",
        "O pré-processamento de dados é uma etapa crucial para preparar os dados para modelagem, garantindo que estejam no formato correto e otimizados para o desempenho do algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "82kzmWnHFkb6"
      },
      "outputs": [],
      "source": [
        "# Separar preditores (X) e variável alvo (y)\n",
        "X = df.drop('Faixa_de_Vendas', axis=1)\n",
        "y = df['Faixa_de_Vendas']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jWU1DMGL6k6P"
      },
      "outputs": [],
      "source": [
        "# Dividir em conjuntos de treino e teste (70% treino, 30% teste)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z9Gt8qdS6n_X"
      },
      "outputs": [],
      "source": [
        "# Verificar as dimensões\n",
        "print(f\"Dimensões de X_train: {X_train.shape}\")\n",
        "print(f\"Dimensões de X_test: {X_test.shape}\")\n",
        "print(f\"Dimensões de y_train: {y_train.shape}\")\n",
        "print(f\"Dimensões de y_test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wQ9wP_zGJkk"
      },
      "source": [
        "## Normalização\n",
        "\n",
        "A normalização escala os dados para um intervalo fixo, geralmente entre 0 e 1. É útil quando o algoritmo de machine learning assume que as características estão em uma escala semelhante.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IHrDH13DHDDU"
      },
      "outputs": [],
      "source": [
        "# Normalização dos dados numéricos com MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WULXU6wBezB5"
      },
      "outputs": [],
      "source": [
        "# Seleciona as colunas numéricas\n",
        "numeric_cols = ['Store_Area', 'Items_Available', 'Daily_Customer_Count', 'Store_Sales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-fHBl47Ve0NM"
      },
      "outputs": [],
      "source": [
        "# Instancia o normalizador\n",
        "scaler_norm = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hynX-y4we3Nb"
      },
      "outputs": [],
      "source": [
        "# Aplica o MinMaxScaler nas colunas numéricas\n",
        "df[numeric_cols] = scaler_norm.fit_transform(df[numeric_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y5Ni6N10HDDU"
      },
      "outputs": [],
      "source": [
        "# Visualiza as 5 primeiras linhas já normalizadas\n",
        "print(\"\\nPrimeiras 5 linhas após normalização:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wVGTMpiF8baX"
      },
      "outputs": [],
      "source": [
        "# Visualização da distribuição da variável normalizada\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df['Store_Sales'], kde=True, color='skyblue')\n",
        "plt.title('Distribuição das Vendas da Loja (Normalizado)')\n",
        "plt.xlabel('Vendas da Loja Normalizadas')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyb-mWfqHDDU"
      },
      "source": [
        "O histograma acima mostra como ficaram os valores de *Store_Sales* depois da normalização com o MinMaxScaler. Agora, todos os números estão entre 0 e 1, mas a forma da distribuição continua a mesma, ou seja, a relação entre os dados foi mantida.\n",
        "Essa etapa é super importante, principalmente quando vamos usar algoritmos de machine learning que são sensíveis à escala. Normalizar os dados ajuda a evitar que variáveis com números maiores acabem tendo mais peso do que deveriam e melhora a performance dos modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOSAwBz0GOAM"
      },
      "source": [
        "## Padronização\n",
        "\n",
        "A padronização (ou Z-score scaling) transforma os dados para ter média 0 e desvio padrão 1. É útil para algoritmos que são sensíveis à escala das características, como SVMs ou redes neurais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "08rFvjoEGxb_"
      },
      "outputs": [],
      "source": [
        "# Importando o StandardScaler para padronização\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HxKYatnGe96h"
      },
      "outputs": [],
      "source": [
        "# Definindo as variáveis numéricas do seu dataset\n",
        "colunas_numericas = ['Store_Area', 'Items_Available', 'Daily_Customer_Count', 'Store_Sales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U5wlJdHKfDdp"
      },
      "outputs": [],
      "source": [
        "# Separando os dados em X (features numéricas)\n",
        "X = df[colunas_numericas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuEUapx7fEzE"
      },
      "outputs": [],
      "source": [
        "# Dividindo em treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(X, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyfnu7jSGxcA"
      },
      "outputs": [],
      "source": [
        "# Instanciando o scaler e ajustando apenas com os dados de treino\n",
        "scaler_std = StandardScaler()\n",
        "X_train_standardized = scaler_std.fit_transform(X_train)\n",
        "X_test_standardized = scaler_std.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUlXrZHy9krS"
      },
      "outputs": [],
      "source": [
        "# Transformando em DataFrame para visualização\n",
        "df_standardized = pd.DataFrame(X_train_standardized, columns=X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjA3XOiN9o4u"
      },
      "outputs": [],
      "source": [
        "# Visualizando as 5 primeiras linhas\n",
        "print(\"Primeiras 5 linhas dos dados padronizados (treino):\")\n",
        "print(df_standardized.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmW0BXwZ-GOY"
      },
      "outputs": [],
      "source": [
        "# Visualização da distribuição após a padronização (usando Store_Sales)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df_standardized['Store_Sales'], kde=True)\n",
        "plt.title('Distribuição das Vendas da Loja (Padronizado)')\n",
        "plt.xlabel('Vendas da Loja Padronizadas')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmeMPbfhGxcA"
      },
      "source": [
        "O histograma de *Store_Sales* após a padronização mostra que os valores foram transformados para uma distribuição centrada, com média próxima de 0 e desvio padrão igual a 1.\n",
        "Esse processo é útil principalmente para algoritmos que assumem que os dados estão em uma escala padronizada, como modelos lineares e redes neurais.\n",
        "Além disso, a padronização facilita a comparação entre variáveis com diferentes unidades de medida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBl8S0hDGap4"
      },
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Agora que já exploramos e tratamos nossos dados, vamos dar um passo além e criar novas variáveis que podem nos ajudar a entender melhor o desempenho das lojas. Vamos combinar colunas existentes para gerar informações mais ricas e úteis para análise.\n",
        "\n",
        "As novas colunas que criei foram:\n",
        "\n",
        "- Vendas por metro quadrado (Vendas_por_m2): mostra o quanto cada loja fatura em média por metro quadrado, ou seja, sua eficiência em vendas.\n",
        "\n",
        "- Clientes por metro quadrado (Clientes_por_m2): indica o fluxo de clientes por área, o que pode sugerir o quão movimentada é a loja.\n",
        "\n",
        "- Itens por cliente (Itens_por_Cliente): calcula a média de itens disponíveis por cliente, o que pode apontar para variedade percebida ou abastecimento.\n",
        "\n",
        "- Ticket médio (Ticket_Medio): mostra quanto, em média, cada cliente gasta por dia na loja.\n",
        "\n",
        "Essas novas variáveis vão nos ajudar a fazer análises mais completas e a tirar conclusões mais relevantes sobre o desempenho de cada loja."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22yH9SUSBU4k"
      },
      "outputs": [],
      "source": [
        "# Criando novas colunas com base em combinações das variáveis existentes\n",
        "df['Vendas_por_m2'] = df['Store_Sales'] / df['Store_Area']\n",
        "df['Clientes_por_m2'] = df['Daily_Customer_Count'] / df['Store_Area']\n",
        "df['Itens_por_Cliente'] = df['Items_Available'] / df['Daily_Customer_Count']\n",
        "df['Ticket_Medio'] = df['Store_Sales'] / df['Daily_Customer_Count']\n",
        "\n",
        "# Visualizando as primeiras linhas do dataset com as novas variáveis\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRRTJq8-Cc-x"
      },
      "source": [
        "Vamos observar como as lojas se distribuem em relação às novas variáveis que criamos. Isso pode nos ajudar a entender padrões interessantes, como lojas com alta eficiência de vendas, ticket médio maior, ou menor densidade de clientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjqmKNGqCcsG"
      },
      "outputs": [],
      "source": [
        "# Importando biblioteca necessária\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMup8HHIMm2O"
      },
      "outputs": [],
      "source": [
        "# Selecionando as colunas novas para análise\n",
        "novas_colunas = ['Vendas_por_m2', 'Clientes_por_m2', 'Itens_por_Cliente', 'Ticket_Medio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naSAgPENMsPo"
      },
      "outputs": [],
      "source": [
        "# Criando histogramas com KDE para visualizar a distribuição dessas variáveis\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "for i, coluna in enumerate(novas_colunas, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.histplot(df[coluna], kde=True, color='mediumseagreen')\n",
        "    plt.title(f'Distribuição de {coluna.replace(\"_\", \" \")}')\n",
        "    plt.xlabel(coluna.replace(\"_\", \" \"))\n",
        "    plt.ylabel('Frequência')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b38Otu9UDPFN"
      },
      "source": [
        "As distribuições das novas variáveis criadas mostram que a maioria das lojas concentra seus resultados em faixas mais baixas, enquanto poucas lojas se destacam com valores significativamente maiores. Isso pode indicar:\n",
        "- Desigualdade de performance entre as lojas;\n",
        "- Oportunidade de replicar estratégias das lojas com melhor desempenho;\n",
        "- Necessidade de investigar outliers (pontos muito fora da curva)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsH2LlbYI3Ue"
      },
      "source": [
        "## Segmentação de Lojas com K-Means: Identificação de Perfis de Desempenho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8riUQU-tH3Hm"
      },
      "outputs": [],
      "source": [
        "# Importando biblioteca necessária\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot7v7rYfMzM1"
      },
      "outputs": [],
      "source": [
        "# Selecionar colunas numéricas para clustering\n",
        "colunas_cluster = ['Store_Area', 'Items_Available', 'Daily_Customer_Count', 'Store_Sales']\n",
        "X = df[colunas_cluster]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXO9ITGyM1MQ"
      },
      "outputs": [],
      "source": [
        "# Normalizar os dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLhiEBE9M3Z3"
      },
      "outputs": [],
      "source": [
        "# Aplicar o KMeans com 3 clusters (pode testar outros depois)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df['Cluster_KMeans'] = kmeans.fit_predict(X_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVvO5l1vM5bJ"
      },
      "outputs": [],
      "source": [
        "# Visualizar a distribuição dos clusters\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(data=df, x='Store_Sales', y='Store_Area', hue='Cluster_KMeans', palette='Set2')\n",
        "plt.title('Clusters de Lojas com base em Vendas e Área')\n",
        "plt.xlabel('Vendas Totais')\n",
        "plt.ylabel('Área da Loja (m²)')\n",
        "plt.legend(title='Cluster')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Ver o perfil médio de cada cluster\n",
        "df.groupby('Cluster_KMeans')[colunas_cluster].mean().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OROw4t-SJASS"
      },
      "source": [
        "**O que a segmentação das lojas nos mostrou?**\n",
        "\n",
        "Através da técnica de K-Means, conseguimos agrupar as lojas com base em características como área da loja, quantidade de itens disponíveis, número de clientes por dia e vendas totais. O objetivo era entender se existiam padrões entre elas — e sim, encontramos três perfis bem diferentes!\n",
        "\n",
        "**Cluster 0 - Azul – Lojas grandes e com bom desempenho**\n",
        "\n",
        "Essas lojas têm a maior média de área e estoque, além de boas vendas. Elas também recebem um número razoável de clientes por dia. Representam aquelas unidades mais estruturadas, provavelmente com espaço de sobra e movimentação constante. Porém, elas não são as mais eficientes em termos de resultado por metro quadrado.\n",
        "\n",
        "---\n",
        "\n",
        "**Cluster 1 - Vermelho – Lojas menores, com desempenho mais fraco**\n",
        "\n",
        "Esse grupo reúne as lojas com menor média de vendas, área e movimento. Elas podem estar localizadas em regiões com menos fluxo de pessoas ou talvez ainda não tenham atingido todo seu potencial. É um grupo que merece atenção, pois aqui pode haver oportunidade de melhoria ou de revisão de estratégia.\n",
        "\n",
        "---\n",
        "\n",
        "**Cluster 2 – Verde - Lojas médias com alta eficiência**\n",
        "\n",
        "Esse grupo foi o mais interessante, porque mesmo sem ser o maior em estrutura ou estoque, são as lojas que mais vendem e mais atendem clientes por dia. Isso indica um nível de eficiência alto e elas aproveitam bem o espaço, têm boa rotatividade e estão em locais estratégicos. Vale a pena investigar o que essas lojas estão fazendo certo e tentar aplicar em outras unidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGLhqrE5PgRl"
      },
      "source": [
        "# Extra: Segmentação de Lojas com KMeans\n",
        "Para ir além da análise exploratória básica, realizamos uma clusterização das lojas com o algoritmo KMeans, com o objetivo de identificar grupos com perfis similares de operação e desempenho. Reduzimos as variáveis numéricas para duas dimensões com PCA (Análise de Componentes Principais) para facilitar a visualização."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4FGoU7DPlaQ"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas necessárias\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Aplicando PCA para reduzir as dimensões para 2 componentes\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(df[numeric_cols])\n",
        "\n",
        "# Aplicando o algoritmo KMeans com 3 clusters (pode testar outros valores também)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_pca)\n",
        "\n",
        "# Adicionando a coluna de cluster ao dataframe\n",
        "df['Cluster'] = clusters\n",
        "\n",
        "# Visualizando os clusters gerados\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette='Set2')\n",
        "plt.title('Clusters de Lojas com PCA + KMeans')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend(title='Cluster')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2q5IH9tP5UO"
      },
      "source": [
        "A análise de clusters revelou **três grupos distintos de lojas**, com base nas variáveis normalizadas. Essa segmentação pode ser útil para:\n",
        "\n",
        "- Identificar lojas com perfil de **alto desempenho (Cluster 2 - verde)**, que tendem a estar posicionadas à direita do gráfico, com valores mais elevados nas componentes principais, sugerindo maior área, fluxo ou vendas.\n",
        "- Entender o **perfil mais modesto (Cluster 1 - laranja)**, localizado à esquerda e mais denso, possivelmente composto por lojas menores ou com menor faturamento.\n",
        "- O **Cluster 0 (azul)** mostra maior dispersão vertical, podendo indicar lojas com variações de performance mais ligadas a uma ou outra variável, como fluxo de clientes ou variedade de itens.\n",
        "\n",
        "Esses grupos podem servir como base para estratégias específicas por perfil de loja: desde ações promocionais, ajustes de sortimento ou mudanças operacionais. O uso de PCA permitiu reduzir a dimensionalidade e visualizar claramente os agrupamentos formados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY_GDjf1G-PM"
      },
      "source": [
        "# Conclusão\n",
        "\n",
        "A análise do dataset de lojas permitiu identificar padrões relevantes de desempenho com base em variáveis como área da loja, quantidade de itens disponíveis, fluxo diário de clientes e vendas totais. A aplicação de técnicas de visualização e análise estatística possibilitou entender a distribuição e a relação entre essas variáveis.\n",
        "\n",
        "Com a criação de novas métricas, como ticket médio e itens por cliente, foi possível enriquecer a análise e avaliar a eficiência operacional das lojas de forma mais completa.\n",
        "\n",
        "A aplicação do algoritmo K-Means para segmentação revelou três grupos distintos de lojas:  \n",
        "- Lojas com grande estrutura e desempenho mediano,  \n",
        "- Lojas com menor estrutura e menor desempenho,  \n",
        "- Lojas com estrutura média e alta eficiência em vendas e atendimento.\n",
        "\n",
        "Esses resultados evidenciam que o desempenho de uma loja não depende apenas de sua estrutura física, mas de como ela é gerida e aproveitada. A análise, mesmo sem o uso de modelos preditivos, foi capaz de gerar insights práticos que podem orientar estratégias de melhoria e tomada de decisão."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}